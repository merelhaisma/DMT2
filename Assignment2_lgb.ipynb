{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:05:54.647783500Z",
     "start_time": "2023-05-21T16:05:54.564604200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:06:00.365647Z",
     "start_time": "2023-05-21T16:05:54.581320800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data into pandas dataframes. The data has to be manually saved to a folder called 'data'.\n",
    "# Note: the data is quite large, so this may take a while (~40 seconds) if the data is read as a csv. To speed up further file reading, it is converted to pickle format.\n",
    "if (os.path.exists(os.path.join('data', 'training_set_VU_DM.pickle'))\n",
    "    & os.path.exists((os.path.join('data', 'test_set_VU_DM.pickle')))):\n",
    "    train_df = pd.read_pickle(os.path.join('data', 'training_set_VU_DM.pickle'))\n",
    "    test_df = pd.read_pickle(os.path.join('data', 'test_set_VU_DM.pickle'))\n",
    "else:\n",
    "    train_df = pd.read_csv(os.path.join('data', 'training_set_VU_DM.csv'))\n",
    "    test_df = pd.read_csv(os.path.join('data', 'test_set_VU_DM.csv'))\n",
    "    train_df.to_pickle(os.path.join('data', 'training_set_VU_DM.pickle'))\n",
    "    test_df.to_pickle(os.path.join('data', 'test_set_VU_DM.pickle'))\n",
    "\n",
    "# train_df = pd.read_csv(os.path.join('data', 'dummy_training.csv'))\n",
    "# test_df = pd.read_csv(os.path.join('data', 'dummy_testing.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:06:02.408975900Z",
     "start_time": "2023-05-21T16:06:00.528920200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period of data collection: 2012/11/01 - 2013/06/30\n",
      "Train data contains 4,958,347 rows and 54 columns\n",
      "Test data contains 4,959,183 rows and 50 columns\n",
      "\n",
      "Train data:\n",
      "Number of unique search IDs: 199,795\n",
      "Number of unique property IDs: 129,113\n",
      "Number of clicks per search: avg. 1.11, std. 0.21\n",
      "Number of bookings per search: avg. 0.69, std. 0.16\n",
      "\n",
      "Test data:\n",
      "Number of unique search IDs: 199,549\n",
      "Number of unique property IDs: 129,438\n"
     ]
    }
   ],
   "source": [
    "print(f\"Period of data collection: {pd.to_datetime(train_df['date_time']).min().strftime('%Y/%m/%d')} - {pd.to_datetime(train_df['date_time']).max().strftime('%Y/%m/%d')}\")\n",
    "print(f\"Train data contains {train_df.shape[0]:,} rows and {train_df.shape[1]} columns\")\n",
    "print(f\"Test data contains {test_df.shape[0]:,} rows and {test_df.shape[1]} columns\")\n",
    "print()\n",
    "print(f\"Train data:\")\n",
    "print(f\"Number of unique search IDs: {len(train_df['srch_id'].unique()):,}\")\n",
    "print(f\"Number of unique property IDs: {len(train_df['prop_id'].unique()):,}\")\n",
    "print(f\"Number of clicks per search: avg. {train_df['click_bool'].sum() / len(train_df['srch_id'].unique()):.2f}, std. {train_df['click_bool'].std():.2f}\")\n",
    "print(f\"Number of bookings per search: avg. {train_df['booking_bool'].sum() / len(train_df['srch_id'].unique()):.2f}, std. {train_df['booking_bool'].std():.2f}\")\n",
    "print()\n",
    "print(f\"Test data:\")\n",
    "print(f\"Number of unique search IDs: {len(test_df['srch_id'].unique()):,}\")\n",
    "print(f\"Number of unique property IDs: {len(test_df['prop_id'].unique()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:06:02.408975900Z",
     "start_time": "2023-05-21T16:06:02.385900Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Create the following new features: has_starrating, has_review_score, traveling_abroad, srch_prop_country_match, month, and day_of_week\n",
    "    \"\"\"\n",
    "    # has_starrating: boolean whether prop_starrating is 0 or null\n",
    "    df[\"has_starrating\"] = df[\"prop_starrating\"].isnull()\n",
    "    df[\"has_starrating\"] = df[\"has_starrating\"].astype(int)\n",
    "    df.loc[df[\"prop_starrating\"] == 0, \"has_starrating\"] = 1\n",
    "\n",
    "    # has_review_score: boolean whether prop_review_score is 0 or null\n",
    "    df[\"has_review_score\"] = df[\"prop_review_score\"].isnull()\n",
    "    df[\"has_review_score\"] = df[\"has_review_score\"].astype(int)\n",
    "    df.loc[df[\"prop_review_score\"] == 0, \"has_review_score\"] = 1\n",
    "\n",
    "    # traveling_abroad: boolean whether visitor_location_country_id != prop_country_id\n",
    "    df[\"traveling_abroad\"] = df[\"visitor_location_country_id\"] != df[\"prop_country_id\"]\n",
    "    df[\"traveling_abroad\"] = df[\"traveling_abroad\"].astype(int)\n",
    "\n",
    "    # srch_prop_country_match: boolean whether srch_destination_id == prop_country_id\n",
    "    df[\"srch_prop_country_match\"] = df[\"srch_destination_id\"] == df[\"prop_country_id\"]\n",
    "    df[\"srch_prop_country_match\"] = df[\"srch_prop_country_match\"].astype(int)\n",
    "\n",
    "    # month: month of the search, one-hot encoded\n",
    "    df[\"date_time\"] = pd.to_datetime(df[\"date_time\"])\n",
    "    df[\"month\"] = df[\"date_time\"].dt.month\n",
    "    df[\"month\"] = df[\"month\"].map({1: \"jan\", 2: \"feb\", 3: \"mar\", 4: \"apr\", 5: \"may\", 6: \"jun\", 7: \"jul\", 8: \"aug\", 9: \"sep\", 10: \"oct\", 11: \"nov\", 12: \"dec\"})\n",
    "    df = pd.get_dummies(df, columns=[\"month\"], dtype=int)\n",
    "    for col in [\"month_jan\", \"month_feb\", \"month_mar\", \"month_apr\", \"month_may\", \"month_jun\", \"month_jul\", \"month_aug\", \"month_sep\", \"month_oct\", \"month_nov\", \"month_dec\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "\n",
    "    # day_of_week: day of the week of the search\n",
    "    df[\"day_of_week\"] = df[\"date_time\"].dt.dayofweek\n",
    "    df[\"day_of_week\"] = df[\"day_of_week\"].map({0: \"mon\", 1: \"tue\", 2: \"wed\", 3: \"thu\", 4: \"fri\", 5: \"sat\", 6: \"sun\"})\n",
    "    df = pd.get_dummies(df, columns=[\"day_of_week\"], dtype=int)\n",
    "    for col in [\"day_of_week_mon\", \"day_of_week_tue\", \"day_of_week_wed\", \"day_of_week_thu\", \"day_of_week_fri\", \"day_of_week_sat\", \"day_of_week_sun\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:06:02.409518900Z",
     "start_time": "2023-05-21T16:06:02.399353900Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_nan_columns(df):\n",
    "    \"\"\"\n",
    "    Train data shows that \"visitor_hist_starrating\", \"visitor_hist_adr_usd\", \"srch_query_affinity_score\", and \"compx_rate_percent_diff\" have >90% NaN values. These values cannot be imputed accurately, so we drop these columns.\n",
    "    \"\"\"\n",
    "    cols = [\"visitor_hist_starrating\", \"visitor_hist_adr_usd\", \"srch_query_affinity_score\"] + [f\"comp{i}_rate_percent_diff\" for i in range(1, 9)]\n",
    "    df.drop(columns=cols, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:06:02.417696Z",
     "start_time": "2023-05-21T16:06:02.407550900Z"
    }
   },
   "outputs": [],
   "source": [
    "def impute_missing_values(df):\n",
    "    \"\"\"\n",
    "    Impute missing values for the following columns: \"prop_starrating\", \"prop_review_score\", \"compx_rate\", and \"compx_inv\".\n",
    "\n",
    "    For \"prop_starrating\" and \"prop_review_score\", we replace 0 values with NaN and then impute the NaN values with the mean per srch_id. Remaining NaN values are then filled with 0.\n",
    "    For \"compx_rate\" and \"compx_inv\", we assume that missing data means that Expedia has the same price and equal availability as its competitors. We therefore impute the NaN values with 0.\n",
    "    \"\"\"\n",
    "    # Replace 0 values with NaN\n",
    "    df[\"prop_starrating\"] = df[\"prop_starrating\"].replace(0, np.nan)\n",
    "    df[\"prop_review_score\"] = df[\"prop_review_score\"].replace(0, np.nan)\n",
    "    # Impute NaN values with mean per srch_id\n",
    "    df[\"prop_starrating\"] = df.groupby(\"srch_id\")[\"prop_starrating\"].transform(lambda x: x.fillna(x.mean()))\n",
    "    df[\"prop_review_score\"] = df.groupby(\"srch_id\")[\"prop_review_score\"].transform(lambda x: x.fillna(x.mean()))\n",
    "    # Fill remaining NaN values with 0\n",
    "    df[\"prop_starrating\"] = df[\"prop_starrating\"].fillna(0)\n",
    "    df[\"prop_review_score\"] = df[\"prop_review_score\"].fillna(0)\n",
    "\n",
    "    # Impute NaN values with 0\n",
    "    for i in range(1, 9):\n",
    "        df[f\"comp{i}_rate\"] = df[f\"comp{i}_rate\"].fillna(0)\n",
    "        df[f\"comp{i}_inv\"] = df[f\"comp{i}_inv\"].fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:06:02.424875700Z",
     "start_time": "2023-05-21T16:06:02.415548500Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_aggregated_values(df):\n",
    "    \"\"\"\n",
    "    Compute the mean, median and standard deviation for the following columns:\n",
    "    \"visitor_hist_starrating\", \"visitor_hist_adr_usd\", \"prop_starrating\", \"prop_review_score\", \"prop_location_score1\", \"prop_log_historical_price\", \"price_usd\"\n",
    "    \"\"\"\n",
    "    numerical_cols = [\"prop_starrating\", \"prop_review_score\", \"prop_location_score1\", \"prop_log_historical_price\", \"price_usd\"]\n",
    "    # srch_length_of_stay, srch_booking_window, srch_adults_count, srch_children_count, and srch_room_count are also numerical variables, but it has no use aggregating these values over prop_id.\n",
    "\n",
    "    agg_df = df.groupby(\"prop_id\").agg({col: [\"mean\", \"std\", \"median\"] for col in numerical_cols})\n",
    "    agg_df.columns = [\"_\".join(col) for col in agg_df.columns]\n",
    "    agg_df.fillna(0, inplace=True)  # Fill standard deviation NaN values with 0\n",
    "    for col in agg_df.columns:\n",
    "        df[col] = df[\"prop_id\"].map(agg_df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:06:02.428976700Z",
     "start_time": "2023-05-21T16:06:02.422827700Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_relative_values(df):\n",
    "    \"\"\"\n",
    "    Subtract the mean per srch_id from the following columns:\n",
    "    \"prop_starrating\", \"prop_review_score\", \"prop_location_score1\", \"prop_log_historical_price\", \"price_usd\"\n",
    "\n",
    "    This is done so that the model can learn the relative values of these columns per srch_id.\n",
    "    \"\"\"\n",
    "    cols = [\"prop_starrating\", \"prop_review_score\", \"prop_location_score1\", \"prop_log_historical_price\", \"price_usd\"]\n",
    "    grouper = df.groupby('srch_id')\n",
    "    for col in cols:\n",
    "        df[col] = df[col] - grouper[col].transform('mean')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:06:02.465472Z",
     "start_time": "2023-05-21T16:06:02.428976700Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    \"\"\"\n",
    "    Train data shows that for \"orig_destination_distance\" over 75% of the data with a calculated value lower than 0.95 of the largest distance was lower than 130, meaning that the distance per srch_id is roughly the same. We assume therefore that this is not a deciding factor for a customer in their booking process and drop this column.\n",
    "\n",
    "    Features were created from \"date_time\" and the column will not be used anymore, so we drop this column as well.\n",
    "\n",
    "    Columns containing IDs (\"site_id\", \"visitor_location_country_id\", \"prop_country_id\", \"prop_id\", and \"srch_destination_id\") are not used in the model, so we drop these columns as well. \"srch_id\" and \"prop_id\" will remain in the columns for now for later use.\n",
    "\n",
    "    If the supplied dataframe is the training dataframe, drop the unused target columns as well.\n",
    "\n",
    "    # TODO:\n",
    "    I don't really know what to do with \"prop_location_score2\" yet, so I'll drop it for now.\n",
    "    \"\"\"\n",
    "    df.drop(columns=[\"orig_destination_distance\"], inplace=True)\n",
    "    df.drop(columns=[\"date_time\"], inplace=True)\n",
    "    df.drop(columns=[\"site_id\", \"visitor_location_country_id\", \"prop_country_id\", \"srch_destination_id\"], inplace=True)\n",
    "    df.drop(columns=[\"prop_location_score2\"], inplace=True)\n",
    "    for col in [\"position\", \"gross_bookings_usd\"]:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:06:02.466490200Z",
     "start_time": "2023-05-21T16:06:02.438851900Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(train_df: pd.DataFrame, test_df: pd.DataFrame, target_value: str = \"booking_bool\"):\n",
    "    \"\"\"\n",
    "    Process the dataframes for training and testing the model.\n",
    "    :param train_df: The training dataframe\n",
    "    :param test_df: The test dataframe\n",
    "    :param target_value: The target value to use for training the model. Either \"booking_bool\" or \"both\".\n",
    "    :return: The processed dataframes\n",
    "    \"\"\"\n",
    "    # Create features\n",
    "    train_df = create_features(train_df)\n",
    "    test_df = create_features(test_df)\n",
    "\n",
    "    # Drop columns with NaN values\n",
    "    train_df = drop_nan_columns(train_df)\n",
    "    test_df = drop_nan_columns(test_df)\n",
    "\n",
    "    # Impute missing values\n",
    "    train_df = impute_missing_values(train_df)\n",
    "    test_df = impute_missing_values(test_df)\n",
    "\n",
    "    # Compute aggregated values\n",
    "    train_df = compute_aggregated_values(train_df)\n",
    "    test_df = compute_aggregated_values(test_df)\n",
    "\n",
    "    # Compute relative values\n",
    "    train_df = compute_relative_values(train_df)\n",
    "    test_df = compute_relative_values(test_df)\n",
    "\n",
    "    # Drop columns\n",
    "    train_df = drop_columns(train_df)\n",
    "    test_df = drop_columns(test_df)\n",
    "\n",
    "    # Split train data into features and target\n",
    "    if target_value == \"booking_bool\":\n",
    "        train_df[\"target\"] = train_df[\"booking_bool\"]\n",
    "    elif target_value == \"both\":\n",
    "        train_df[\"target\"] = 5*train_df[\"booking_bool\"] + train_df[\"click_bool\"]\n",
    "    else:\n",
    "        raise ValueError(\"target_value must be either 'booking_bool' or 'both'\")\n",
    "\n",
    "    train_df.drop(columns=[\"booking_bool\", \"click_bool\"], inplace=True)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:06:02.466490200Z",
     "start_time": "2023-05-21T16:06:02.445997500Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sequences(df: pd.DataFrame, kind: str = \"train\") -> dict:\n",
    "    \"\"\"\n",
    "    Generate sequences from the dataframe.\n",
    "    :param df: The dataframe to take the sequences from.\n",
    "    :param kind: The kind of dataframe. Either \"train\" or \"test\".\n",
    "    :return: Dictionary containing the sequences and targets for the training data.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    if kind == \"train\":\n",
    "        idx_dict = df.to_dict(\"index\")\n",
    "        df = df.drop(columns=[\"prop_id\", \"srch_id\", \"target\"])\n",
    "        for i, idx in enumerate(tqdm(idx_dict, desc=\"Train DataLoader\")):\n",
    "            sequences.append({\"srch_id\": idx_dict[idx][\"srch_id\"], \"prop_id\": idx_dict[idx][\"prop_id\"], \"sequence\": df.iloc[i].values, \"target\": idx_dict[idx][\"target\"]})\n",
    "    elif kind == \"test\":\n",
    "        idx_dict = df.to_dict(\"index\")\n",
    "        df = df.drop(columns=[\"prop_id\", \"srch_id\"])\n",
    "        for i, idx in enumerate(tqdm(idx_dict, desc=\"Test DataLoader\")):\n",
    "            sequences.append({\"srch_id\": idx_dict[idx][\"srch_id\"], \"prop_id\": idx_dict[idx][\"prop_id\"], \"sequence\": df.iloc[i].values})\n",
    "    else:\n",
    "        raise ValueError(\"kind must be either 'train' or 'test'\")\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:06:02.466490200Z",
     "start_time": "2023-05-21T16:06:02.454745200Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_lgb_sequences(train_df, test_df, force_data_processing=False):\n",
    "    \"\"\"\n",
    "    Generate the train and test dictionaries\n",
    "    \"\"\"\n",
    "    if os.path.exists(os.path.join('data', f'train_sequences_both.pickle')) \\\n",
    "            & os.path.exists(os.path.join('data', f'test_sequences_both.pickle')) \\\n",
    "            & (not force_data_processing):\n",
    "        print(f\"Loading train and test sequences from pickle files...\")\n",
    "        with open(os.path.join('data', f'train_sequences_both.pickle'), 'rb') as f:\n",
    "            train_sequences = pickle.load(f)\n",
    "        with open(os.path.join('data', f'test_sequences_both.pickle'), 'rb') as f:\n",
    "            test_sequences = pickle.load(f)\n",
    "    else:\n",
    "        processed_train_df, processed_test_df = process_data(train_df, test_df, target_value=\"both\")\n",
    "        train_sequences = generate_sequences(processed_train_df, kind=\"train\")\n",
    "        with open(os.path.join('data', f'train_sequences_both.pickle'), 'wb') as f:\n",
    "            pickle.dump(train_sequences, f)\n",
    "        test_sequences = generate_sequences(processed_test_df, kind=\"test\")\n",
    "        with open(os.path.join('data', f'test_sequences_both.pickle'), 'wb') as f:\n",
    "            pickle.dump(test_sequences, f)\n",
    "\n",
    "    return train_sequences, test_sequences\n",
    "\n",
    "def generate_lgb_data(sequences, kind=\"train\"):\n",
    "    train_x = np.array([seq[\"sequence\"] for seq in sequences])\n",
    "    \n",
    "    query_to_properties = {}\n",
    "    for seq in sequences:\n",
    "        \n",
    "        srch_id = seq[\"srch_id\"]\n",
    "        prop_id = seq[\"prop_id\"]\n",
    "        # Add the search ID to the dictionary if it isn't in already\n",
    "        if srch_id not in query_to_properties.keys():\n",
    "            query_to_properties[srch_id] = []\n",
    "        \n",
    "        query_to_properties[srch_id].append(prop_id)\n",
    "\n",
    "    # When generating train data, return also targets\n",
    "    if kind==\"train\":\n",
    "        train_y = np.array([seq[\"target\"] for seq in sequences])\n",
    "\n",
    "        return train_x, train_y, query_to_properties\n",
    "    \n",
    "    # When generating test data, return only features and query information\n",
    "    elif kind==\"test\":\n",
    "\n",
    "        return train_x, query_to_properties\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset creation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the LambdaMART model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:07:51.909928400Z",
     "start_time": "2023-05-21T16:06:02.464457300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sequences...\n",
      "Loading train and test sequences from pickle files...\n",
      "Done generating sequences. This took 45.46s\n",
      "Generating train features...\n",
      "Done generating train features. This took 26.58s\n",
      "Transforming train features into appropriate dataset...\n",
      "Done generating dataset. This took 0.04s\n",
      "Training model...\n",
      "Done training model. This took 36.75s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<lightgbm.basic.Booster at 0x2abd19d6c90>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "# Assume X_train and y_train are the training features and target values, respectively\n",
    "print(\"Generating sequences...\")\n",
    "t = time.time()\n",
    "lgb_train_sequences, lgb_test_sequences = generate_lgb_sequences(train_df, test_df)\n",
    "print(f\"Done generating sequences. This took {time.time() - t:.2f}s\")\n",
    "\n",
    "t = time.time()\n",
    "print(\"Generating train features...\")\n",
    "train_x, train_y, train_queries = generate_lgb_data(lgb_train_sequences, kind=\"train\")\n",
    "print(f\"Done generating train features. This took {time.time() - t:.2f}s\")\n",
    "\n",
    "t = time.time()\n",
    "print(\"Transforming train features into appropriate dataset...\")\n",
    "# Create a LightGBM dataset from the training data\n",
    "train_data = lgb.Dataset(train_x, label=train_y, group=[len(elem) for elem in train_queries.values()])\n",
    "print(f\"Done generating dataset. This took {time.time() - t:.2f}s\")\n",
    "\n",
    "# Set the parameters for the LambdaMART model\n",
    "params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_eval_at': [5],  # Evaluation at NDCG@5\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'device': 'gpu' # Change to GPU if available\n",
    "}\n",
    "\n",
    "# Train the LambdaMART model\n",
    "num_rounds = 100\n",
    "\n",
    "t = time.time()\n",
    "print(\"Training model...\")\n",
    "model = lgb.train(params, train_data, num_rounds)\n",
    "print(f\"Done training model. This took {time.time() - t:.2f}s\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save_model('lambda_mart_model.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the LambdaMART model and save the output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:07:52.241679600Z",
     "start_time": "2023-05-21T16:07:51.915096800Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_and_write(fn, predictions, queries):\n",
    "\n",
    "    srch_to_ranks = {}\n",
    "    \n",
    "    i=0\n",
    "    for query_id, property_ids in tqdm(queries.items()):\n",
    "        \n",
    "        # Retrieve all probabilities for a certain query ID (assuming the data is still ordered)\n",
    "        ranks = predictions[i:i+len(property_ids)]\n",
    "\n",
    "        # Keep track of the probabilities\n",
    "        srch_to_ranks[query_id] = ranks\n",
    "        i+=len(property_ids)\n",
    "    \n",
    "    # Write predictions to file\n",
    "    with open(fn, \"w\") as f:\n",
    "        f.write(\"srch_id,prop_id\\n\")\n",
    "\n",
    "        # Iterate over all different queries\n",
    "        for srch_id, srch_probs in srch_to_ranks.items():\n",
    "            \n",
    "            # Get the order of the hotels based on the predicted probabilities\n",
    "            sorted_indices = np.array(srch_probs).argsort()[::-1]\n",
    "            property_ids_sorted = np.array(queries[srch_id])[np.array(sorted_indices)]\n",
    "\n",
    "            for s_id, p_id in zip([srch_id for _ in range(len(property_ids_sorted))],property_ids_sorted):\n",
    "                f.write(f\"{s_id},{p_id}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T16:08:38.823697200Z",
     "start_time": "2023-05-21T16:07:51.915096800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22006296 -0.2416695  -0.30013754 ... -0.72995487 -0.63153378\n",
      " -0.24392625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199549/199549 [00:00<00:00, 1124304.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get the test data\n",
    "test_x, test_queries = generate_lgb_data(lgb_test_sequences, kind=\"test\")\n",
    "\n",
    "predictions = model.predict(test_x, raw_score=False)\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)\n",
    "\n",
    "# Write predictions to file\n",
    "test_and_write(\"test_output/LambdaMART_vanilla.csv\", predictions, test_queries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
